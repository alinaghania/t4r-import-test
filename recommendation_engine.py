"""
MODULE: MOTEUR DE RECOMMANDATION
===============================

Ce module g√®re l'inf√©rence et les pr√©dictions du mod√®le Transformer
pour fournir des recommandations de produits en temps r√©el.

Auteur: Assistant AI & Alina Ghani
Date: Juillet 2025
"""

import torch
import torch.nn as nn
import numpy as np
import pandas as pd
import logging
from typing import List, Dict, Tuple, Optional, Union
from pathlib import Path

from .transformer_model import TransformerRecommendationModel

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class RecommendationEngine:
    """
    Moteur de recommandation bas√© sur le mod√®le Transformer.

    Cette classe g√®re:
    - Le chargement du mod√®le entra√Æn√©
    - L'inf√©rence en temps r√©el
    - L'√©valuation des performances
    - L'explication des pr√©dictions
    """

    def __init__(
        self,
        model_path: str = None,
        device: str = "auto",
        model: TransformerRecommendationModel = None,
    ):
        """
        Initialise le moteur de recommandation.

        Args:
            model_path: Chemin vers le mod√®le sauvegard√©
            device: Device d'inf√©rence ('auto', 'cpu', 'cuda')
            model: Mod√®le pr√©-charg√© (optionnel)
        """
        # Configuration du device
        if device == "auto":
            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        else:
            self.device = torch.device(device)

        # Charger le mod√®le
        if model is not None:
            self.model = model
            self.model.to(self.device)
        elif model_path:
            self.model = self._load_model(model_path)
        else:
            raise ValueError("Vous devez fournir soit model_path soit model")

        # Mode √©valuation
        self.model.eval()

        logger.info("üîÆ Pr√©dicteur initialis√©:")
        logger.info(f"  ‚Ä¢ Device: {self.device}")
        logger.info(f"  ‚Ä¢ Items: {self.model.num_items}")
        logger.info(f"  ‚Ä¢ S√©quence max: {self.model.seq_length}")

    def _load_model(self, model_path: str) -> TransformerRecommendationModel:
        """
        Charge le mod√®le depuis un fichier.

        Args:
            model_path: Chemin vers le mod√®le

        Returns:
            TransformerRecommendationModel: Mod√®le charg√©
        """
        logger.info(f"üìÇ Chargement du mod√®le: {model_path}")

        checkpoint = torch.load(model_path, map_location=self.device)
        config = checkpoint["model_config"]

        # Cr√©er le mod√®le avec la configuration sauvegard√©e
        model = TransformerRecommendationModel(**config)
        model.load_state_dict(checkpoint["model_state_dict"])
        model.to(self.device)

        logger.info("‚úÖ Mod√®le charg√© avec succ√®s!")

        return model

    def _preprocess_sequence(self, sequence: List[int]) -> torch.Tensor:
        """
        Pr√©processe une s√©quence pour l'inf√©rence.

        Args:
            sequence: Liste d'IDs de produits

        Returns:
            torch.Tensor: S√©quence preprocess√©e [1, seq_length]
        """
        # Convertir en liste si n√©cessaire
        if isinstance(sequence, (np.ndarray, torch.Tensor)):
            sequence = sequence.tolist()

        # Filtrer les valeurs nulles ou n√©gatives
        sequence = [item for item in sequence if item > 0]

        # Tronquer si trop long
        if len(sequence) > self.model.seq_length:
            sequence = sequence[-self.model.seq_length :]

        # Padding si trop court
        if len(sequence) < self.model.seq_length:
            # Padding au d√©but (style GPT)
            padding_length = self.model.seq_length - len(sequence)
            sequence = [0] * padding_length + sequence

        # Convertir en tenseur
        tensor = torch.LongTensor(sequence).unsqueeze(0)  # [1, seq_length]
        tensor = tensor.to(self.device)

        return tensor

    def predict_single(
        self, sequence: List[int], top_k: int = 5, return_probabilities: bool = True
    ) -> Dict:
        """
        Fait une pr√©diction pour une s√©quence unique.

        Args:
            sequence: Historique des produits consult√©s
            top_k: Nombre de recommandations √† retourner
            return_probabilities: Retourner les probabilit√©s

        Returns:
            dict: R√©sultats de pr√©diction
        """
        self.model.eval()

        with torch.no_grad():
            # Pr√©processer la s√©quence
            input_tensor = self._preprocess_sequence(sequence)

            # Forward pass
            logits = self.model(input_tensor)

            # Convertir en probabilit√©s
            probabilities = torch.softmax(logits, dim=-1)

            # Top-K pr√©dictions
            top_probs, top_indices = torch.topk(probabilities, k=top_k, dim=-1)

            # Extraire les r√©sultats
            predicted_items = top_indices.squeeze().cpu().numpy().tolist()
            predicted_probs = top_probs.squeeze().cpu().numpy().tolist()

            # Pr√©parer les r√©sultats
            results = {
                "predicted_items": predicted_items,
                "input_sequence": sequence,
                "preprocessed_sequence": input_tensor.squeeze().cpu().numpy().tolist(),
            }

            if return_probabilities:
                results["probabilities"] = predicted_probs
                results["confidence"] = max(predicted_probs)

            return results

    def predict_batch(
        self,
        sequences: List[List[int]],
        top_k: int = 5,
        return_probabilities: bool = False,
    ) -> List[Dict]:
        """
        Fait des pr√©dictions pour un batch de s√©quences.

        Args:
            sequences: Liste de s√©quences √† pr√©dire
            top_k: Nombre de recommandations par s√©quence
            return_probabilities: Retourner les probabilit√©s

        Returns:
            list: Liste des r√©sultats de pr√©diction
        """
        self.model.eval()

        results = []

        with torch.no_grad():
            # Preprocesser toutes les s√©quences
            batch_tensors = []
            for seq in sequences:
                tensor = self._preprocess_sequence(seq)
                batch_tensors.append(tensor)

            # Concatener en batch
            batch_input = torch.cat(batch_tensors, dim=0)  # [batch_size, seq_length]

            # Forward pass
            logits = self.model(batch_input)

            # Convertir en probabilit√©s
            probabilities = torch.softmax(logits, dim=-1)

            # Top-K pour chaque s√©quence
            top_probs, top_indices = torch.topk(probabilities, k=top_k, dim=-1)

            # Extraire les r√©sultats pour chaque s√©quence
            for i, original_seq in enumerate(sequences):
                predicted_items = top_indices[i].cpu().numpy().tolist()

                result = {
                    "predicted_items": predicted_items,
                    "input_sequence": original_seq,
                }

                if return_probabilities:
                    predicted_probs = top_probs[i].cpu().numpy().tolist()
                    result["probabilities"] = predicted_probs
                    result["confidence"] = max(predicted_probs)

                results.append(result)

        return results

    def explain_prediction(self, sequence: List[int], top_k: int = 5) -> Dict:
        """
        Fournit une explication d√©taill√©e d'une pr√©diction.

        Args:
            sequence: S√©quence d'entr√©e
            top_k: Nombre de pr√©dictions √† expliquer

        Returns:
            dict: Explication d√©taill√©e
        """
        # Faire la pr√©diction de base
        prediction = self.predict_single(
            sequence, top_k=top_k, return_probabilities=True
        )

        # Analyse de la s√©quence
        unique_items = len(set([x for x in sequence if x > 0]))
        sequence_length = len([x for x in sequence if x > 0])

        # Calcul de la diversit√© des pr√©dictions
        predicted_items = prediction["predicted_items"]
        diversity_score = len(set(predicted_items)) / len(predicted_items)

        # Explication
        explanation = {
            "prediction_summary": prediction,
            "sequence_analysis": {
                "original_length": sequence_length,
                "unique_items": unique_items,
                "diversity_ratio": unique_items / max(sequence_length, 1),
                "most_recent_items": sequence[-3:] if len(sequence) >= 3 else sequence,
            },
            "prediction_analysis": {
                "diversity_score": diversity_score,
                "confidence_level": prediction.get("confidence", 0),
                "top_prediction": predicted_items[0] if predicted_items else None,
            },
            "recommendations": [],
        }

        # Ajouter des recommandations explicites
        for i, (item, prob) in enumerate(
            zip(predicted_items, prediction.get("probabilities", []))
        ):
            explanation["recommendations"].append(
                {
                    "rank": i + 1,
                    "item_id": item,
                    "probability": prob,
                    "confidence_level": "High"
                    if prob > 0.3
                    else "Medium"
                    if prob > 0.1
                    else "Low",
                }
            )

        return explanation

    def evaluate_model(
        self,
        test_sequences: List[List[int]],
        test_targets: List[int],
        metrics: List[str] = ["accuracy@1", "accuracy@5", "mrr"],
    ) -> Dict:
        """
        √âvalue les performances du mod√®le sur des donn√©es de test.

        Args:
            test_sequences: S√©quences de test
            test_targets: Vrais prochains items
            metrics: M√©triques √† calculer

        Returns:
            dict: R√©sultats d'√©valuation
        """
        logger.info(
            f"üìä √âvaluation du mod√®le sur {len(test_sequences)} √©chantillons..."
        )

        self.model.eval()

        # Pr√©dictions
        predictions = self.predict_batch(
            test_sequences, top_k=10, return_probabilities=False
        )

        # Calcul des m√©triques
        results = {}

        if "accuracy@1" in metrics:
            correct_at_1 = sum(
                1
                for pred, target in zip(predictions, test_targets)
                if pred["predicted_items"][0] == target
            )
            results["accuracy@1"] = correct_at_1 / len(test_sequences)

        if "accuracy@5" in metrics:
            correct_at_5 = sum(
                1
                for pred, target in zip(predictions, test_targets)
                if target in pred["predicted_items"][:5]
            )
            results["accuracy@5"] = correct_at_5 / len(test_sequences)

        if "mrr" in metrics:
            mrr_scores = []
            for pred, target in zip(predictions, test_targets):
                try:
                    rank = pred["predicted_items"].index(target) + 1
                    mrr_scores.append(1.0 / rank)
                except ValueError:
                    mrr_scores.append(0.0)
            results["mrr"] = np.mean(mrr_scores)

        logger.info("‚úÖ √âvaluation termin√©e:")
        for metric, value in results.items():
            logger.info(f"  ‚Ä¢ {metric}: {value:.4f}")

        return results

    def get_item_embeddings(self, item_ids: List[int]) -> np.ndarray:
        """
        Retourne les embeddings des items sp√©cifi√©s.

        Args:
            item_ids: Liste d'IDs d'items

        Returns:
            np.ndarray: Embeddings [n_items, embedding_dim]
        """
        self.model.eval()

        with torch.no_grad():
            item_tensor = torch.LongTensor(item_ids).to(self.device)
            embeddings = self.model.get_embeddings(item_tensor)

            return embeddings.cpu().numpy()

    def find_similar_items(
        self, item_id: int, top_k: int = 10, similarity_metric: str = "cosine"
    ) -> List[Tuple[int, float]]:
        """
        Trouve les items similaires √† un item donn√©.

        Args:
            item_id: ID de l'item de r√©f√©rence
            top_k: Nombre d'items similaires √† retourner
            similarity_metric: M√©trique de similarit√© ('cosine', 'euclidean')

        Returns:
            list: Liste de tuples (item_id, similarity_score)
        """
        # Obtenir tous les embeddings
        all_item_ids = list(range(1, self.model.num_items + 1))
        all_embeddings = self.get_item_embeddings(all_item_ids)

        # Embedding de l'item de r√©f√©rence
        ref_embedding = self.get_item_embeddings([item_id])[0]

        # Calcul des similarit√©s
        if similarity_metric == "cosine":
            # Similarit√© cosinus
            similarities = np.dot(all_embeddings, ref_embedding) / (
                np.linalg.norm(all_embeddings, axis=1) * np.linalg.norm(ref_embedding)
            )
        elif similarity_metric == "euclidean":
            # Distance euclidienne (convertie en similarit√©)
            distances = np.linalg.norm(all_embeddings - ref_embedding, axis=1)
            similarities = 1 / (1 + distances)
        else:
            raise ValueError(f"M√©trique non support√©e: {similarity_metric}")

        # Trier et retourner les top-K (en excluant l'item lui-m√™me)
        sorted_indices = np.argsort(similarities)[::-1]

        similar_items = []
        for idx in sorted_indices:
            current_item_id = all_item_ids[idx]
            if current_item_id != item_id:  # Exclure l'item lui-m√™me
                similar_items.append((current_item_id, similarities[idx]))
                if len(similar_items) >= top_k:
                    break

        return similar_items


def main():
    """Fonction principale pour test du module."""
    print("=" * 60)
    print("üîÆ TEST DU MOTEUR DE RECOMMANDATION")
    print("=" * 60)

    # Cr√©er un mod√®le de test
    model = TransformerRecommendationModel(
        num_items=50, embedding_dim=64, seq_length=10, num_heads=4, num_layers=2
    )

    # Cr√©er le moteur de recommandation
    engine = RecommendationEngine(model=model, device="cpu")

    # Test de pr√©diction simple
    test_sequence = [1, 15, 23, 8, 42]
    print(f"\nüìä Test de pr√©diction:")
    print(f"  ‚Ä¢ S√©quence: {test_sequence}")

    prediction = engine.predict_single(test_sequence, top_k=5)
    print(f"  ‚Ä¢ Pr√©dictions: {prediction['predicted_items']}")
    print(f"  ‚Ä¢ Probabilit√©s: {[f'{p:.3f}' for p in prediction['probabilities']]}")

    # Test de pr√©diction batch
    batch_sequences = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
    batch_predictions = engine.predict_batch(batch_sequences, top_k=3)

    print(f"\nüìä Test de pr√©diction batch:")
    for i, pred in enumerate(batch_predictions):
        print(
            f"  ‚Ä¢ S√©quence {i + 1}: {pred['input_sequence']} ‚Üí {pred['predicted_items']}"
        )

    # Test d'explication
    explanation = engine.explain_prediction(test_sequence, top_k=3)
    print(f"\nüìã Explication d√©taill√©e:")
    print(f"  ‚Ä¢ Items uniques: {explanation['sequence_analysis']['unique_items']}")
    print(
        f"  ‚Ä¢ Confiance: {explanation['prediction_analysis']['confidence_level']:.3f}"
    )

    # Test de similarit√©
    similar_items = engine.find_similar_items(item_id=1, top_k=5)
    print(f"\nüîç Items similaires √† l'item 1:")
    for item_id, similarity in similar_items:
        print(f"  ‚Ä¢ Item {item_id}: {similarity:.3f}")

    print("\n‚úÖ Tous les tests du moteur de recommandation sont pass√©s!")


if __name__ == "__main__":
    main()
