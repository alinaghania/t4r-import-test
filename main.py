"""
PIPELINE PRINCIPAL: SYST√àME DE RECOMMANDATION TRANSFORMER
=========================================================

Ce script orchestre le pipeline complet de recommandation de produits:
1. G√©n√©ration de donn√©es synth√©tiques
2. Preprocessing des s√©quences
3. Entra√Ænement du mod√®le Transformer
4. D√©monstration d'inf√©rence

Usage:
    python main.py [mode]

Modes disponibles:
    - full: Pipeline complet (d√©faut)
    - data: G√©n√©ration de donn√©es seulement
    - train: Entra√Ænement seulement
    - inference: Inf√©rence seulement
    - demo: D√©monstration interactive

"""

import os
import sys
import time
import argparse
import logging
from pathlib import Path

# Import des modules du syst√®me de recommandation
from src import (
    SyntheticDataGenerator,
    SequenceDataPreprocessor,
    TransformerRecommendationModel,
    ModelTrainer,
    RecommendationEngine,
)

# Configuration du logging
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class RecommendationPipeline:
    """
    Pipeline principal pour le syst√®me de recommandation.

    G√®re l'orchestration compl√®te du syst√®me:
    - G√©n√©ration/chargement des donn√©es
    - Preprocessing des s√©quences
    - Entra√Ænement du mod√®le
    - Inf√©rence et recommandations
    """

    def __init__(
        self,
        data_dir="data",
        models_dir="models",
        n_customers=1000,
        n_products=50,
        n_sessions=5000,
    ):
        """
        Initialise le pipeline.

        Args:
            data_dir: R√©pertoire des donn√©es
            models_dir: R√©pertoire des mod√®les
            n_customers: Nombre de clients pour la g√©n√©ration
            n_products: Nombre de produits
            n_sessions: Nombre de sessions
        """
        self.data_dir = Path(data_dir)
        self.models_dir = Path(models_dir)

        # Configuration des donn√©es
        self.n_customers = n_customers
        self.n_products = n_products
        self.n_sessions = n_sessions

        # Chemins des fichiers
        self.raw_data_path = self.data_dir / "raw_transactions.parquet"
        self.training_data_path = self.data_dir / "training_data.pt"
        self.model_path = self.models_dir / "transformer_recommendation_model.pt"

        # Cr√©er les r√©pertoires
        self.data_dir.mkdir(exist_ok=True)
        self.models_dir.mkdir(exist_ok=True)

        logger.info("üèóÔ∏è Pipeline initialis√©:")
        logger.info(f"  ‚Ä¢ R√©pertoire donn√©es: {self.data_dir}")
        logger.info(f"  ‚Ä¢ R√©pertoire mod√®les: {self.models_dir}")
        logger.info(f"  ‚Ä¢ Configuration: {n_customers} clients, {n_products} produits")

    def run_data_generation(self):
        """G√©n√®re les donn√©es synth√©tiques."""
        logger.info("=" * 60)
        logger.info("üìä √âTAPE 1: G√âN√âRATION DES DONN√âES")
        logger.info("=" * 60)

        # Cr√©er le g√©n√©rateur
        generator = SyntheticDataGenerator(
            n_customers=self.n_customers,
            n_products=self.n_products,
            n_sessions=self.n_sessions,
            random_seed=42,
        )

        # G√©n√©rer et sauvegarder
        df, _ = generator.generate_and_save(str(self.raw_data_path))

        logger.info(f"‚úÖ Donn√©es g√©n√©r√©es: {len(df):,} transactions")

        return df

    def run_preprocessing(self):
        """Preprocesse les donn√©es en s√©quences."""
        logger.info("=" * 60)
        logger.info("‚öôÔ∏è √âTAPE 2: PREPROCESSING DES DONN√âES")
        logger.info("=" * 60)

        # Cr√©er le preprocesseur
        preprocessor = SequenceDataPreprocessor(max_seq_length=10)

        # Pipeline complet de preprocessing
        results = preprocessor.full_preprocessing_pipeline(
            data_path=str(self.raw_data_path),
            output_training_path=str(self.training_data_path),
        )

        logger.info(
            f"‚úÖ Preprocessing termin√©: {results['stats']['num_sequences']:,} s√©quences"
        )

        return results

    def run_training(self):
        """Entra√Æne le mod√®le Transformer."""
        logger.info("=" * 60)
        logger.info("üöÄ √âTAPE 3: ENTRA√éNEMENT DU MOD√àLE")
        logger.info("=" * 60)

        # Charger les donn√©es d'entra√Ænement
        from src.model_trainer import load_training_data

        inputs, targets = load_training_data(str(self.training_data_path))

        # Cr√©er le mod√®le
        model = TransformerRecommendationModel(
            num_items=self.n_products,
            embedding_dim=64,
            seq_length=10,
            num_heads=4,
            num_layers=2,
            dropout=0.1,
        )

        # Cr√©er l'entra√Æneur
        trainer = ModelTrainer(
            model=model, device="auto", learning_rate=1e-3, batch_size=64
        )

        # Entra√Æner le mod√®le
        history = trainer.train(
            inputs=inputs,
            targets=targets,
            num_epochs=5,
            val_split=0.2,
            save_path=str(self.model_path),
            save_best=True,
            verbose=True,
        )

        final_train_loss = history["train_loss"][-1]
        final_val_loss = history["val_loss"][-1]

        logger.info("‚úÖ Entra√Ænement termin√©:")
        logger.info(f"  ‚Ä¢ Loss finale train: {final_train_loss:.4f}")
        logger.info(f"  ‚Ä¢ Loss finale validation: {final_val_loss:.4f}")

        return history

    def run_inference_demo(self):
        """D√©monstration d'inf√©rence avec le mod√®le entra√Æn√©."""
        logger.info("=" * 60)
        logger.info("üîÆ √âTAPE 4: D√âMONSTRATION D'INF√âRENCE")
        logger.info("=" * 60)

        # Cr√©er le moteur de recommandation
        engine = RecommendationEngine(model_path=str(self.model_path), device="auto")

        # Exemples de d√©monstration
        demo_cases = [
            {
                "name": "Client jeune actif",
                "description": "Jeune professionnel qui d√©bute",
                "sequence": [1, 15, 23],
            },
            {
                "name": "Famille en croissance",
                "description": "Famille qui investit dans l'immobilier",
                "sequence": [5, 12, 34, 8],
            },
            {
                "name": "Investisseur exp√©riment√©",
                "description": "Client fortun√© avec portefeuille diversifi√©",
                "sequence": [2, 45, 18, 31, 7],
            },
            {
                "name": "Retrait√© prudent",
                "description": "Client senior s√©curisant son patrimoine",
                "sequence": [8, 22, 41],
            },
        ]

        logger.info("üîç D√©monstration de pr√©dictions:")

        for i, case in enumerate(demo_cases, 1):
            logger.info(f"\nüìä Exemple {i}: {case['name']}")
            logger.info(f"   Description: {case['description']}")
            logger.info(f"   Historique: {case['sequence']}")

            # Faire la pr√©diction
            prediction = engine.predict_single(
                sequence=case["sequence"], top_k=5, return_probabilities=True
            )

            # Afficher les r√©sultats
            logger.info(f"   üéØ Pr√©dictions Top-5:")
            for j, (item, prob) in enumerate(
                zip(prediction["predicted_items"], prediction["probabilities"]), 1
            ):
                logger.info(f"      {j}. Produit {item} | Probabilit√©: {prob:.1%}")

        # Explication d√©taill√©e pour le premier cas
        first_case = demo_cases[0]
        explanation = engine.explain_prediction(first_case["sequence"], top_k=5)

        logger.info(f"\nüìã Explication d√©taill√©e pour {first_case['name']}:")
        logger.info(
            f"   ‚Ä¢ S√©quence pr√©process√©e: {explanation['prediction_summary']['preprocessed_sequence']}"
        )
        logger.info(
            f"   ‚Ä¢ Items uniques: {explanation['sequence_analysis']['unique_items']}"
        )
        logger.info(
            f"   ‚Ä¢ Confiance mod√®le: {explanation['prediction_analysis']['confidence_level']:.3f}"
        )

        logger.info(f"\n‚úÖ D√©monstration termin√©e!")

        return engine

    def run_full_pipeline(self):
        """Ex√©cute le pipeline complet."""
        start_time = time.time()

        logger.info("=" * 60)
        logger.info("üéØ D√âMARRAGE DU PIPELINE COMPLET")
        logger.info("=" * 60)

        try:
            # 1. G√©n√©ration des donn√©es
            self.run_data_generation()

            # 2. Preprocessing
            self.run_preprocessing()

            # 3. Entra√Ænement
            self.run_training()

            # 4. D√©monstration
            self.run_inference_demo()

            # Temps total
            total_time = time.time() - start_time

            logger.info("=" * 60)
            logger.info("üéâ PIPELINE TERMIN√â AVEC SUCC√àS! üéâ")
            logger.info("=" * 60)
            logger.info(f"‚è±Ô∏è  Temps total: {total_time:.1f}s")
            logger.info(f"üìÅ Mod√®le sauvegard√©: {self.model_path}")
            logger.info("üöÄ Le syst√®me de recommandation est pr√™t pour la production!")

        except Exception as e:
            logger.error(f"‚ùå Erreur dans le pipeline: {e}")
            raise


def main():
    """Fonction principale avec gestion des arguments."""
    parser = argparse.ArgumentParser(
        description="Pipeline de recommandation Transformer",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemples d'usage:
  python main.py                    # Pipeline complet
  python main.py --mode data        # G√©n√©ration de donn√©es seulement
  python main.py --mode train       # Entra√Ænement seulement
  python main.py --mode inference   # Inf√©rence seulement
  python main.py --customers 2000   # 2000 clients au lieu de 1000
        """,
    )

    parser.add_argument(
        "--mode",
        choices=["full", "data", "preprocess", "train", "inference", "demo"],
        default="full",
        help="Mode d'ex√©cution (d√©faut: full)",
    )

    parser.add_argument(
        "--customers",
        type=int,
        default=1000,
        help="Nombre de clients pour la g√©n√©ration (d√©faut: 1000)",
    )

    parser.add_argument(
        "--products", type=int, default=50, help="Nombre de produits (d√©faut: 50)"
    )

    parser.add_argument(
        "--sessions", type=int, default=5000, help="Nombre de sessions (d√©faut: 5000)"
    )

    parser.add_argument(
        "--data-dir", default="data", help="R√©pertoire des donn√©es (d√©faut: data)"
    )

    parser.add_argument(
        "--models-dir", default="models", help="R√©pertoire des mod√®les (d√©faut: models)"
    )

    args = parser.parse_args()

    # Cr√©er le pipeline
    pipeline = RecommendationPipeline(
        data_dir=args.data_dir,
        models_dir=args.models_dir,
        n_customers=args.customers,
        n_products=args.products,
        n_sessions=args.sessions,
    )

    # Ex√©cuter selon le mode
    try:
        if args.mode == "full":
            pipeline.run_full_pipeline()
        elif args.mode == "data":
            pipeline.run_data_generation()
        elif args.mode == "preprocess":
            pipeline.run_preprocessing()
        elif args.mode == "train":
            pipeline.run_training()
        elif args.mode in ["inference", "demo"]:
            pipeline.run_inference_demo()

    except KeyboardInterrupt:
        logger.info("\n‚ö†Ô∏è Pipeline interrompu par l'utilisateur")
        sys.exit(1)
    except Exception as e:
        logger.error(f"‚ùå Erreur fatale: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
